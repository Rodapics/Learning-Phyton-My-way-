{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a29169-2018-4c09-ac24-2a590e28daa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b15b0d-3253-4747-8581-65b6f07ca129",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Numpy Vs Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af5f89-4bb0-4f98-a91e-9b455ef43106",
   "metadata": {},
   "source": [
    "Pytorch es un opaquete es nos permitirá a los usuarios crear entornos de entramiento de los estados creados en machinearning/deep learning, además, lo utilizaremos para simplificar el tiempo de calculo de los procesores utilziados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d7871cd-e4e3-4534-9156-24dbf54f91fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Numpy Vs Torch\n",
    "\n",
    "n = np.linspace(0,1,5)   #Crea un array\n",
    "t = torch.linspace(0,1,5)   #Crea un tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69112996-c187-4055-9e57-4fd2834b0e41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.25, 0.5 , 0.75, 1.  ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2aec8676-d4a9-4bc6-8dc5-d78a8f2eefeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b3c88e7-2d07-48e4-97eb-81fb252f5648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Se puede redefinir su tamaño de forma similar:\n",
    "\n",
    "\n",
    "#np.arange(x), permite crear x elementos.\n",
    "\n",
    "n = np.arange(48).reshape(3,4,4)     #Primer término: np.arange(x), indica el número de elementos que tendrá el array.\n",
    "t = torch.arange(48).reshape(3,4,4)  #Primer término: reshape(x,y,y) indica el número de divisiones que tendra el array y cómo se acomodará.\n",
    "                                     #Hay que tener en cuenta que 48=3*4*4\n",
    "                                     #reshape(x,0,0): indica la dimensión del array\n",
    "                                     #reshape(0,x,0): indica las divisiones del array\n",
    "                                     #reshape(0,0,x): indica los numeros de elemntos por divisiones en el array.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c81f026-66e6-4d49-ae18-ca0e8bad34d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]],\n",
       "\n",
       "       [[16, 17, 18, 19],\n",
       "        [20, 21, 22, 23],\n",
       "        [24, 25, 26, 27],\n",
       "        [28, 29, 30, 31]],\n",
       "\n",
       "       [[32, 33, 34, 35],\n",
       "        [36, 37, 38, 39],\n",
       "        [40, 41, 42, 43],\n",
       "        [44, 45, 46, 47]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0600c33-978f-4fa0-a23e-d3ab27814e70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15]],\n",
       "\n",
       "        [[16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [24, 25, 26, 27],\n",
       "         [28, 29, 30, 31]],\n",
       "\n",
       "        [[32, 33, 34, 35],\n",
       "         [36, 37, 38, 39],\n",
       "         [40, 41, 42, 43],\n",
       "         [44, 45, 46, 47]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ce5250-0d77-42e5-80fa-7ccc349b24d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Es importante tener en cuenta que, ambas librerias tienes las mismas reglas de transmisión o \"Broadcasting rules\".\n",
    "Estas reglas se hablaran a continuación y se usan para trabjar de manera más eficiente con esta libreria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b4858-517b-4130-a830-57d831f22e47",
   "metadata": {},
   "source": [
    "# Reglas Generales de Transmisión - Broadcasting Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9234792-1e07-48af-a493-e20c7c265f00",
   "metadata": {},
   "source": [
    "Cuando se operan con dos arrays, NumPy realizar la comparación de la forma de sus elementales.\n",
    "Este empieza con la dimensionan final (empezando en la derecha) y trabajando hacia la izquierda. Dos dimensiones son compatibles sii:\n",
    "* Son iguales, o\n",
    "* Una de ellas es igual a 1.\n",
    "\n",
    "*A continuacion de presenta un ejemplo*: Las dos siguientes son iguales:\n",
    "\n",
    "6-D array\n",
    "\n",
    "Shape 1: (1,6,4,1,7,2)    \n",
    "\n",
    "Shape 2: (5,6,1,3,1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bffc4ee-1b12-4374-92d2-622189b8f7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.ones((6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b318fced-e94d-4618-8932-43c73d58fc51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de747af1-24cf-4f8e-82b5-a0ad205ac6c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "392175dc-0bcd-4440-93ce-9d05fbc6a75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = np.arange(5).reshape(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7ca6d67c-cb42-494c-af32-0254f8d59305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c41f581-6cbd-4296-a1fd-f4b8877d8456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fdc19-1482-4cfc-ad56-d81345629fc8",
   "metadata": {},
   "source": [
    "Vemos que tanto a como b cumplen la regla de Broadcasting, y pueden operar aritmericamente entre ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "285b15e8-04d9-4b09-a05e-226a8a732e43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.],\n",
       "       [1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad812556-f168-4f6b-ad21-c80e10692cb5",
   "metadata": {},
   "source": [
    "Manera similar para pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "053963ea-5d47-475a-a74a-ea016fb5edfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.ones((6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "39724429-e182-48ba-b96f-6ad32e6e520b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8278bbb3-483a-49db-9569-8ab6edc332cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eb673553-7214-48a5-9118-44e251c76e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = torch.arange(5).reshape((1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b8d467a-6388-4533-9dae-e582659562cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "edc21228-3762-4b1c-bc03-647f67b1fb72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "86c214bc-0e3f-4ba1-b29e-562627ec391f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823ce9b-8843-498b-9bca-b381b85f1176",
   "metadata": {},
   "source": [
    "Ejemplo: Esaclar cada canal de color de un canal por una cantidad diferente:\n",
    "\n",
    "Image (3d array): 256 x 256 x 3 \n",
    "\n",
    "Scale (1d array):           x 3 \n",
    "\n",
    "Result (3d array):256 x 256 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "897e892d-056b-4c58-9aea-ec0d1c410bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image = torch.randn((256,256,3))\n",
    "Scale = torch.tensor([0.5,1.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7f5df985-770d-46f5-a43f-c8e03a7e6066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4380, -0.0646,  1.1617],\n",
       "         [ 1.9910,  2.6149, -0.7018],\n",
       "         [ 0.7084,  0.2115,  0.2887],\n",
       "         ...,\n",
       "         [-0.0531,  1.7332, -1.8491],\n",
       "         [-0.1330, -0.0340,  1.0178],\n",
       "         [ 0.3894,  0.8846,  0.8746]],\n",
       "\n",
       "        [[-1.3944, -1.2168, -0.3124],\n",
       "         [-1.4399,  0.0253,  1.2241],\n",
       "         [ 1.2480, -0.8514, -1.9048],\n",
       "         ...,\n",
       "         [-0.6295, -0.0271,  0.9641],\n",
       "         [-0.6879, -1.3520, -0.7752],\n",
       "         [ 1.8647, -1.7098, -1.7209]],\n",
       "\n",
       "        [[-0.3068, -2.1579, -1.1805],\n",
       "         [-0.7247,  0.9899, -0.9158],\n",
       "         [-0.0480,  1.4102, -1.7402],\n",
       "         ...,\n",
       "         [ 1.4566,  1.1486,  0.0396],\n",
       "         [ 1.1208, -1.0850, -0.8937],\n",
       "         [-0.4337,  0.1638,  0.1576]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9731,  0.0742, -1.2102],\n",
       "         [ 1.7489, -0.9656,  0.7161],\n",
       "         [-0.1075, -0.4320, -1.0777],\n",
       "         ...,\n",
       "         [-0.1369,  1.1503, -0.6220],\n",
       "         [-1.5659, -0.5805, -0.0238],\n",
       "         [-0.5006,  0.6346, -0.6074]],\n",
       "\n",
       "        [[-0.4770,  0.6502, -0.1591],\n",
       "         [ 1.2546, -0.4129, -0.7308],\n",
       "         [ 0.2036,  0.0794, -0.2488],\n",
       "         ...,\n",
       "         [-0.3534,  0.5604, -0.4668],\n",
       "         [ 1.9981, -0.4166,  0.5390],\n",
       "         [-2.4692,  0.2753, -1.2440]],\n",
       "\n",
       "        [[ 0.0357, -0.1902, -1.5783],\n",
       "         [ 0.1831, -0.3074, -0.1795],\n",
       "         [ 0.6252, -0.6122,  0.0205],\n",
       "         ...,\n",
       "         [ 0.2987,  0.6432,  0.1917],\n",
       "         [ 0.9796, -0.6527, -0.4001],\n",
       "         [ 1.0653,  0.2025, -0.7819]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4c8f5811-2355-44c6-930a-fde4f9e6d9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.5000, 1.0000])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9f755c4d-e184-481e-ac24-7e1357f3a08b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Result = Image*Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5428b9b0-427b-49a4-ad13-5dd9dc05f5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2190, -0.0969,  1.1617],\n",
       "         [ 0.9955,  3.9224, -0.7018],\n",
       "         [ 0.3542,  0.3172,  0.2887],\n",
       "         ...,\n",
       "         [-0.0266,  2.5999, -1.8491],\n",
       "         [-0.0665, -0.0510,  1.0178],\n",
       "         [ 0.1947,  1.3269,  0.8746]],\n",
       "\n",
       "        [[-0.6972, -1.8253, -0.3124],\n",
       "         [-0.7200,  0.0379,  1.2241],\n",
       "         [ 0.6240, -1.2771, -1.9048],\n",
       "         ...,\n",
       "         [-0.3148, -0.0406,  0.9641],\n",
       "         [-0.3440, -2.0280, -0.7752],\n",
       "         [ 0.9323, -2.5647, -1.7209]],\n",
       "\n",
       "        [[-0.1534, -3.2368, -1.1805],\n",
       "         [-0.3624,  1.4848, -0.9158],\n",
       "         [-0.0240,  2.1153, -1.7402],\n",
       "         ...,\n",
       "         [ 0.7283,  1.7228,  0.0396],\n",
       "         [ 0.5604, -1.6274, -0.8937],\n",
       "         [-0.2169,  0.2457,  0.1576]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4866,  0.1113, -1.2102],\n",
       "         [ 0.8745, -1.4484,  0.7161],\n",
       "         [-0.0537, -0.6480, -1.0777],\n",
       "         ...,\n",
       "         [-0.0684,  1.7255, -0.6220],\n",
       "         [-0.7830, -0.8707, -0.0238],\n",
       "         [-0.2503,  0.9520, -0.6074]],\n",
       "\n",
       "        [[-0.2385,  0.9753, -0.1591],\n",
       "         [ 0.6273, -0.6193, -0.7308],\n",
       "         [ 0.1018,  0.1191, -0.2488],\n",
       "         ...,\n",
       "         [-0.1767,  0.8405, -0.4668],\n",
       "         [ 0.9990, -0.6249,  0.5390],\n",
       "         [-1.2346,  0.4130, -1.2440]],\n",
       "\n",
       "        [[ 0.0178, -0.2853, -1.5783],\n",
       "         [ 0.0915, -0.4611, -0.1795],\n",
       "         [ 0.3126, -0.9184,  0.0205],\n",
       "         ...,\n",
       "         [ 0.1494,  0.9648,  0.1917],\n",
       "         [ 0.4898, -0.9791, -0.4001],\n",
       "         [ 0.5326,  0.3037, -0.7819]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5faad3d-fa65-4f16-8a33-7e0ee54b9890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646dca6-bf06-4357-8f31-49da05241400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717f773-2934-48d3-9d27-726e275d4717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bea91674-3815-438d-a7d6-839530facae7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Terminal de Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03d2b8a7-b3ad-478f-acfc-f9e50d90bc80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de2e3b5c-0eb2-4976-83c9-0887a70a260d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.array(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70da51ee-b868-4363-a1ba-70e9919fc419",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13760212-69c8-4ea1-bf7f-315878561d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.array(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e313feb-9177-4ebf-a0da-e9113b7cb44a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "874f01d6-40a4-4aad-9a8d-1972a9e09a33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b5436b0-6038-4d66-97b7-b0df091ec867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.array([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8c248ab0-0515-4fd0-8760-f4c61300bd15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.array([7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2af875a9-429c-447a-ac44-3f6d7e4a6897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c67ef208-0ccc-4c5d-ab15-ee9a4266f3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4068639-ad49-4cf6-bcaf-29ec40135611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "afb24a07-1c11-40b4-965b-435cb546b71f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1= torch.tensor((3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1e467586-a5c6-4971-a595-d9f73cc8a10b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "00bbc3bd-2ed9-4311-90a7-f54f9ee39385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x2 = torch.tensor([3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d456018d-4764-4377-924f-e88222ce318e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9d5bb424-0c34-4a8b-bf92-9101c3c29fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 == x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "483668d2-650e-4fa1-a618-6c442c6e02c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4669,  1.4576, -2.6692],\n",
       "         [-0.5733, -0.0362,  0.6935]],\n",
       "\n",
       "        [[ 0.1292, -0.4471, -1.9122],\n",
       "         [-0.0876, -0.4642, -0.9346]],\n",
       "\n",
       "        [[-0.6746, -0.4166,  0.8815],\n",
       "         [-0.9591,  1.4819, -2.2322]],\n",
       "\n",
       "        [[-0.3944, -0.0707, -0.2502],\n",
       "         [-0.1049,  2.3924,  0.9855]],\n",
       "\n",
       "        [[-0.3656, -0.7815,  0.6114],\n",
       "         [-0.7343,  1.2421, -2.4393]]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((5,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9724a12-b9b5-46fc-8f37-8a1cf23323d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ebc0f-c38e-4bf5-81ad-abd815dee8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
